{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1-toxvaldb-results-analysis\n",
    "The distribution of ROC-AUC values for the toxvaldb prediction pipeline is unusual. There are some assays with a ROC AUC score of 0, NaN, and 1. I need to take a further look at the scoring files as well as the composition of the assays themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "The unusual scores result from the small testing set sizes. I have included three examples below to explain cases where ROC AUC scores are 1, 0, and NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick prediction score check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import click\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "import selfies as sf\n",
    "import numpy as np\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../data/processed/scores/\"\n",
    "\n",
    "# Get a list of all Parquet files in the folder\n",
    "parquet_files = [f for f in os.listdir(folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "# Initialize an empty list to hold dataframes\n",
    "df_list = []\n",
    "\n",
    "for file in parquet_files:\n",
    "    temp_df = pd.read_parquet(os.path.join(folder_path, file))\n",
    "    temp_df['filename'] = os.path.basename(file)\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "# Read in all Parquet files and concatenate them into a single DataFrame\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# Add a new column with the characters between the 1st and 3rd underscores of the basename\n",
    "df['assay'] = df['filename'].apply(lambda x: '_'.join(x.split('_')[1:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc_roc</th>\n",
       "      <th>filename</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>assay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>score_assay_56_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assay_56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>score_assay_61_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>0.851535</td>\n",
       "      <td>assay_61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>score_assay_72_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>assay_72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>score_assay_89_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>assay_89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>score_assay_45_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>assay_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>score_assay_38_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>0.709669</td>\n",
       "      <td>assay_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>score_assay_6_toxvaldb_2023_logistic_regressio...</td>\n",
       "      <td>0.703077</td>\n",
       "      <td>assay_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>score_assay_63_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>assay_63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>score_assay_29_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>0.754195</td>\n",
       "      <td>assay_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>score_assay_54_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>0.320635</td>\n",
       "      <td>assay_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>score_assay_47_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assay_47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>score_assay_4_toxvaldb_2023_logistic_regressio...</td>\n",
       "      <td>0.804475</td>\n",
       "      <td>assay_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>score_assay_70_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>assay_70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>score_assay_76_toxvaldb_2023_logistic_regressi...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>assay_76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>score_assay_2_toxvaldb_2023_logistic_regressio...</td>\n",
       "      <td>0.704861</td>\n",
       "      <td>assay_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  accuracy  precision    recall        f1   auc_roc  \\\n",
       "0    1024  1.000000   0.000000  0.000000  0.000000       NaN   \n",
       "0    1024  0.714286   0.687500  0.785714  0.733333  0.841837   \n",
       "0    1024  0.500000   0.000000  0.000000  0.000000  0.500000   \n",
       "0    1024  0.714286   0.666667  0.666667  0.666667  0.583333   \n",
       "0    1024  0.750000   0.500000  1.000000  0.666667  1.000000   \n",
       "0    1024  0.677419   0.588235  0.769231  0.666667  0.756410   \n",
       "0    1024  0.444444   0.500000  0.400000  0.444444  0.575000   \n",
       "0    1024  0.750000   0.000000  0.000000  0.000000  1.000000   \n",
       "0    1024  0.375000   0.600000  0.272727  0.375000  0.600000   \n",
       "0    1024  0.285714   0.000000  0.000000  0.000000  0.000000   \n",
       "0    1024  0.000000   0.000000  0.000000  0.000000       NaN   \n",
       "0    1024  0.611111   0.666667  0.600000  0.631579  0.675000   \n",
       "0    1024  1.000000   1.000000  1.000000  1.000000  1.000000   \n",
       "0    1024  0.750000   0.500000  1.000000  0.666667  0.666667   \n",
       "0    1024  0.444444   0.400000  0.500000  0.444444  0.500000   \n",
       "\n",
       "                                            filename    auc_pr     assay  \n",
       "0  score_assay_56_toxvaldb_2023_logistic_regressi...       NaN  assay_56  \n",
       "0  score_assay_61_toxvaldb_2023_logistic_regressi...  0.851535  assay_61  \n",
       "0  score_assay_72_toxvaldb_2023_logistic_regressi...  0.583333  assay_72  \n",
       "0  score_assay_89_toxvaldb_2023_logistic_regressi...  0.555556  assay_89  \n",
       "0  score_assay_45_toxvaldb_2023_logistic_regressi...  1.000000  assay_45  \n",
       "0  score_assay_38_toxvaldb_2023_logistic_regressi...  0.709669  assay_38  \n",
       "0  score_assay_6_toxvaldb_2023_logistic_regressio...  0.703077   assay_6  \n",
       "0  score_assay_63_toxvaldb_2023_logistic_regressi...  1.000000  assay_63  \n",
       "0  score_assay_29_toxvaldb_2023_logistic_regressi...  0.754195  assay_29  \n",
       "0  score_assay_54_toxvaldb_2023_logistic_regressi...  0.320635  assay_54  \n",
       "0  score_assay_47_toxvaldb_2023_logistic_regressi...       NaN  assay_47  \n",
       "0  score_assay_4_toxvaldb_2023_logistic_regressio...  0.804475   assay_4  \n",
       "0  score_assay_70_toxvaldb_2023_logistic_regressi...  1.000000  assay_70  \n",
       "0  score_assay_76_toxvaldb_2023_logistic_regressi...  0.500000  assay_76  \n",
       "0  score_assay_2_toxvaldb_2023_logistic_regressio...  0.704861   assay_2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a few strange sets of results here:\n",
    "- assay_56: it has an accuracy of 1, but values of 0 for precision, recall, and f1, and NaN for auc-roc.\n",
    "- assay_45: accuracy of 0.75, but auc-roc of 1\n",
    "- assay_54: accuracy of 0.29, but auc-roc of 0\n",
    "\n",
    "I will dig further into each of these assays to try and work out what has gone wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assay_56\n",
    "I want to start by having a look at the predictions that were made for this assay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_proba</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CCOCC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.241170</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COc1cc(-c2ccc(/N=N/c3ccc4c(S(=O)(=O)[O-])cc(S(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032146</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cc1cc(-c2ccc(N=Nc3c(S(=O)(=O)O)cc4cc(S(=O)(=O)...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047591</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CC(Cl)(Cl)Cl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238468</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     canonical_smiles  preds  preds_proba  \\\n",
       "8                                               CCOCC      0     0.241170   \n",
       "10  COc1cc(-c2ccc(/N=N/c3ccc4c(S(=O)(=O)[O-])cc(S(...      0     0.032146   \n",
       "11  Cc1cc(-c2ccc(N=Nc3c(S(=O)(=O)O)cc4cc(S(=O)(=O)...      0     0.047591   \n",
       "16                                       CC(Cl)(Cl)Cl      0     0.238468   \n",
       "\n",
       "    ground_truth                model  \n",
       "8              0  logistic_regression  \n",
       "10             0  logistic_regression  \n",
       "11             0  logistic_regression  \n",
       "16             0  logistic_regression  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assay_56_preds = pd.read_parquet(\"/Users/sethhowes/Desktop/FS-Tox/data/processed/predictions/assay_56_toxvaldb_2023_logistic_regression_ecfp4_1024.parquet\")\n",
    "assay_56_preds.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it appears that there is a very small test set consisting of only 6 values. Each of these values is classed as non-toxic. I want to see if there is an error in the toxicity binarisation process whereby all of the values are being classed as non-toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21\n",
       "1     4\n",
       "Name: ground_truth, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assay_56 = pd.read_parquet(\"/Users/sethhowes/Desktop/FS-Tox/data/processed/assays/assay_56_toxvaldb_2023.parquet\")\n",
    "assay_56[\"ground_truth\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are only 4 values that are being classed as toxic. I have a feeling that this could be due to there only being two different numeric outcomes for observations in this assay.\n",
    "\n",
    "In order to read the original numeric values prior to binarisation, I will have to repeat the processing steps carried out in `src/data/raw_to_assays.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert InChI to SMILES\n",
    "def convert_to_smiles(inchi):\n",
    "\n",
    "    # Suppress RDKit warnings\n",
    "    RDLogger.DisableLog(\"rdApp.*\")\n",
    "    \n",
    "    mol = Chem.MolFromInchi(inchi)\n",
    "    if mol is None:\n",
    "        return 'InvalidInChI'  # Placeholder for invalid InChI\n",
    "    smiles = Chem.MolToSmiles(mol)\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of columns to include\n",
    "def get_assays(input_filepath, identifier):\n",
    "\n",
    "    vars_to_extract = [\n",
    "        \"dtxsid\",\n",
    "        \"casrn\",\n",
    "        \"long_ref\",\n",
    "        \"toxval_type\",\n",
    "        \"common_name\",\n",
    "        \"exposure_route\",\n",
    "        \"toxval_units\",\n",
    "        \"study_type\",\n",
    "        \"source\",\n",
    "        \"toxval_numeric\",\n",
    "        \"toxval_numeric_qualifier\",\n",
    "    ]\n",
    "\n",
    "    df = pd.read_csv(input_filepath, usecols=vars_to_extract)\n",
    "\n",
    "    # Replace '-' with np.nan\n",
    "    df.replace(\"-\", np.nan, inplace=True)\n",
    "\n",
    "    assay_components = [\n",
    "        \"long_ref\",\n",
    "        \"toxval_type\",\n",
    "        \"common_name\",\n",
    "        \"exposure_route\",\n",
    "        \"toxval_units\",\n",
    "        \"study_type\",\n",
    "        \"source\",\n",
    "    ]\n",
    "\n",
    "    # Drop rows with null values for key variables\n",
    "    df.dropna(subset=assay_components + [\"toxval_numeric\"], inplace=True)\n",
    "\n",
    "    # Drop long refs with different NA formats\n",
    "    na_list = [\"- - - NA\", \"- - - -\", \"- Unnamed - NA\", \"Unknown\", \"- Unnamed - -\"]\n",
    "    df = df[~df[\"long_ref\"].isin(na_list)]\n",
    "\n",
    "    # Remove those records with toxval_numeric_qualifier not equal to \"=\"\n",
    "    df = df[df[\"toxval_numeric_qualifier\"] != \"=\"]\n",
    "\n",
    "    # Drop the toxval_numeric_qualifier column as it is no longer needed\n",
    "    df.drop(columns=\"toxval_numeric_qualifier\", inplace=True)\n",
    "\n",
    "    # Read in the identifiers\n",
    "    identifiers = pd.read_csv(identifier)\n",
    "\n",
    "    # Merge tox data with the molecule identifiers\n",
    "    df_with_inchis = df.merge(identifiers, how=\"left\", on=\"dtxsid\")\n",
    "\n",
    "    # Apply the function to each value in the Series\n",
    "    smiles_series = df_with_inchis[\"inchi\"].astype(str).apply(convert_to_smiles)\n",
    "\n",
    "    # Reset index to ensure smiles series appends correctly\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Add the smiles column to the DataFrame\n",
    "    df[\"smiles\"] = smiles_series\n",
    "\n",
    "    # Drop rows where smiles column is equal to 'InvalidInChI'\n",
    "    df = df[df[\"smiles\"] != \"InvalidInChI\"]\n",
    "\n",
    "    # Get records that belong to a group of greater than 10 members\n",
    "    df = df.groupby(assay_components).filter(lambda x: len(x) >= 24)\n",
    "\n",
    "    # Replace all '_' with '-' in long_ref column\n",
    "    df[\"long_ref\"] = df[\"long_ref\"].str.replace(\"_\", \"-\")\n",
    "\n",
    "    # Create a new column that is a combination of the assay_components\n",
    "    df[\"combined\"] = df[assay_components].apply(\n",
    "        lambda row: \"_\".join(row.values.astype(str)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a pivot table where each unique combination forms a separate column\n",
    "    df_pivoted = df.pivot_table(\n",
    "        index=\"smiles\",\n",
    "        columns=\"combined\",\n",
    "        values=\"toxval_numeric\",\n",
    "        aggfunc=np.mean,\n",
    "    )\n",
    "\n",
    "    return df_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath = \"/Users/sethhowes/Desktop/FS-Tox/data/raw/toxvaldb_2023.csv\"\n",
    "identifier = \"/Users/sethhowes/Desktop/FS-Tox/data/external/DSSTox_Identifiers_and_CASRN_2021r1.csv\"\n",
    "\n",
    "assays = get_assays(input_filepath, identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/p54ybn1n4j3_ywd21t7skv2m0000gn/T/ipykernel_55656/842036901.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assay_56_raw.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "assay_56_colname = assays.columns[assays.columns.str.startswith(\"Jpn. J. Toxicol. Environ. Health32(1):\")]\n",
    "assay_56_raw = assays[assay_56_colname]\n",
    "assay_56_raw.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jpn. J. Toxicol. Environ. Health32(1): 46-53 Tsuji,S., Y. Tonogai, Y. Ito, and S. Kanoh The Influence of Rearing Temperatures on the Toxicity of Various Environmental Pollutants for Killifish (Oryzias latipes) 1986_LC50_Japanese Medaka_aqueous_mg/m3_mortality_ECOTOX\n",
       "1000000.0                                                                                                                                                                                                                                                                     21\n",
       "10000000.0                                                                                                                                                                                                                                                                     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assay_56_raw.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the reason there is an imbalance when it should be a 50/50 split is that there are only two values. I must therefore remove those assays for which there are only 2 values.\n",
    "\n",
    "So in conclusion, the reason that we are getting the strange evaluation metrics for this assay is that there are no positive cases in the test set. As such, the numerators of the equations for calculating precision and recall are both 0. Additionally, the aur-roc curve will have a true positive rate of 0, as there are no true positives.\n",
    "\n",
    "Accuracy is therefore the only metric that accounts for true negative values, hence why it is positive whilst the rest are negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assay_45\n",
    "This assay has the following scores: accuracy of 0.75, but auc-roc of 1.\n",
    "\n",
    "As I did previously, I will start off by checking the raw predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_proba</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CCCCCC[C@H](C/C=C\\CCCCCCCC(=O)OCCOC)OC(C)=O</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942744</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C1COCCN1.Cl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101234</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>COC(=O)C1=C(C)NC(C)=C(C(=O)OCCN(C)Cc2ccccc2)C1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495211</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>COCCCO</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876955</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     canonical_smiles  preds  preds_proba  \\\n",
       "5         CCCCCC[C@H](C/C=C\\CCCCCCCC(=O)OCCOC)OC(C)=O      1     0.942744   \n",
       "15                                        C1COCCN1.Cl      0     0.101234   \n",
       "19  COC(=O)C1=C(C)NC(C)=C(C(=O)OCCN(C)Cc2ccccc2)C1...      0     0.495211   \n",
       "20                                             COCCCO      1     0.876955   \n",
       "\n",
       "    ground_truth                model  \n",
       "5              1  logistic_regression  \n",
       "15             0  logistic_regression  \n",
       "19             0  logistic_regression  \n",
       "20             0  logistic_regression  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assay_45_preds = pd.read_parquet(\"/Users/sethhowes/Desktop/FS-Tox/data/processed/predictions/assay_45_toxvaldb_2023_logistic_regression_ecfp4_1024.parquet\")\n",
    "assay_45_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 0.75 as the 3/4 predictions are correct.\n",
    "\n",
    "I will now calculate the roc-auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the predicted probabilities and actual labels\n",
    "predicted_probs = assay_45_preds[\"preds_proba\"]\n",
    "actual_labels = assay_45_preds[\"ground_truth\"]\n",
    "\n",
    "# Calculate ROC AUC score using roc_auc_score()\n",
    "roc_auc = roc_auc_score(actual_labels, predicted_probs)\n",
    "\n",
    "# Print the ROC AUC score\n",
    "print(\"ROC AUC score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC is a rank-based metric. It is calculated by constructing the ROC curve for n-1 thresholds, where n is the number of predictions made (in this case 4). For every threshold calculated, the true positive rate will be 1, as there is only one positive prediction made by the model. Therefore for all values of the false positive rate, the true positive rate will always be 1, resulting in a ROC AUC score of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assay_54\n",
    "A reminder of the scores for this assay - accuracy of 0.29, but auc-roc of 0.\n",
    "\n",
    "As I did previously, I want to check the predictions made for this assay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_proba</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNC(=N)S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435951</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sc1nc2ccc(Cl)cc2[nH]1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472622</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C=CCN=C(S)Nc1ccccc1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100480</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CCCCCCCCN(C)CCCCCCCC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679625</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CN1C2CCC(C)(C)C1CC(OC(=O)C(O)(c1cccs1)c1cccs1)C2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.537331</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SC(=NNc1ccccc1)NNc1ccccc1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182318</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SC1=NCCS1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343517</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    canonical_smiles  preds  preds_proba  \\\n",
       "4                                           CNC(=N)S      0     0.435951   \n",
       "13                             Sc1nc2ccc(Cl)cc2[nH]1      0     0.472622   \n",
       "16                               C=CCN=C(S)Nc1ccccc1      0     0.100480   \n",
       "19                              CCCCCCCCN(C)CCCCCCCC      1     0.679625   \n",
       "20  CN1C2CCC(C)(C)C1CC(OC(=O)C(O)(c1cccs1)c1cccs1)C2      1     0.537331   \n",
       "21                         SC(=NNc1ccccc1)NNc1ccccc1      0     0.182318   \n",
       "28                                         SC1=NCCS1      0     0.343517   \n",
       "\n",
       "    ground_truth                model  \n",
       "4              0  logistic_regression  \n",
       "13             0  logistic_regression  \n",
       "16             1  logistic_regression  \n",
       "19             0  logistic_regression  \n",
       "20             0  logistic_regression  \n",
       "21             1  logistic_regression  \n",
       "28             1  logistic_regression  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assay_54_preds = pd.read_parquet(\"/Users/sethhowes/Desktop/FS-Tox/data/processed/predictions/assay_54_toxvaldb_2023_logistic_regression_ecfp4_1024.parquet\")\n",
    "assay_54_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again see how these outputs now make sense. The model is correctly classifying 2/7 observations, hence an accuracy of 0.29.\n",
    "\n",
    "However, it is not correctly classifying any true positives, which means that the true positive rate is 0, and therefore the ROC AUC score is 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
